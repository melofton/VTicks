---
title: "Bayesian_NIMBLE_Assignment"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(nimble)
library(rjags)
library(lubridate)
library(tidybayes)
library(tidyverse)
```

## Read in and wrangle data
```{r}
ticks <- read_csv("../0_Data_files/ticks-targets.csv.gz")
drivers <- read.csv("../0_Data_files/PRISM_data/combined_prism_drivers.csv")

data = drivers%>%
  rename(time = Date,
         siteID = Site)%>%
  mutate(time = as.Date(time))%>%
  left_join(ticks)

#KEY CHANGE: limiting to only timepoints when we have observations - since we are not currently using state-space anyway, no need to include NA observations at this time, and it facilitates convergence
data1 <- data %>%
  filter(year(time) %in% c(2016:2018)) %>%
  mutate(NewEpiWeek = epiweek(time)) %>%
  filter(NewEpiWeek %in% c(09:49)) %>%
  mutate(NewEpiWeek = sprintf("%02d", NewEpiWeek),
         Year = year(time)) %>%
  gather(ambloyomma_americanum:ixodes_scapularis, key = "Species", value = "Count") %>%
  select(-Plot) %>%
  rename(Site = siteID,
         Date = time,
         Plot = plotID,
         Temp_C = tmean..degrees.C.,
         Precip_mm = ppt..mm.) %>%
  select(Site, Year, Date, Plot, Count, Species, Temp_C, Precip_mm) %>%
  filter(!is.na(Count) & Species == "ambloyomma_americanum") %>%
  arrange(Plot)

# Set up array for state-space model
tick.plots <- unique(data1$Plot)
nplots <- length(tick.plots)
time_length <- rep(NA,nplots)

for (i in 1:length(tick.plots)){
  plot.data <- subset(data1, Plot == tick.plots[i])
  time_length[i] <- length(plot.data$Count)
}

y <- array(NA, dim = c(nplots, max(time_length)+1))
x <- array(NA, dim = c(nplots, max(time_length)+1))

for (i in 1:length(tick.plots)){
  plot.data <- subset(data1, Plot == tick.plots[i])
  y[i,c(2:(time_length[i]+1))] <- plot.data$Count
  x[i,c(2:(time_length[i]+1))] <- plot.data$Temp_C
}

# Set up indices
plots <- as.numeric(factor(unique(data1$Plot)))

# # plots 2, 15, 17 have non-zero mean plot effect estimates
# unique(data1$Plot)
# # ORNL_002, TALL_002, UKFS_001
# check <- data1 %>%
#   group_by(Plot) %>%
#   summarize(mean_count = mean(Count, na.rm = TRUE)) %>%
#   arrange(mean_count)
# # it is because they have the highest mean count
```
Summary of work so far:
- model converges fine as random walk. sd_proc is large (1.7-1.8 in log space)  
- cannot estimate both mu and sd of a plot or a site effect. plot was a little closer to converging so worked with that from there on out  
- if we assume mu = 0 for the prior on plot effect, we can estimate an sd  
- however, the plot effect itself is quite small and not distinguishable from 0 when modeled as an additive effect EXCEPT for the three sites w/ the highest counts
- same is true when plot effect is modeled as a multiplicative effect (which I guess would mean the degree of autocorrelation varies by plot?)  
- bottom line not sure the plots/sites are talking to each other much or that this helps us  
- global bias term (b0) converges fine; median is 0.027   
- cannot estimate an autocorrelation term (b1); however this could be because there are arbitrary distances between data points right now

Next steps:
- get regular time series for each plot to properly assess autocorrelation
```{r}
tick_model <- nimbleCode({

  # Priors
  
  #process error
  sd_proc ~ dgamma(0.01, 0.01)
  
  # #random effects (or fixed effects? I am not sure how you would code that up differently)
  # sd_plot ~ dgamma(0.01, 0.01)

  #process parameters
  b1 ~ dnorm(0,100)
  # bx ~ dnorm(0,100)
  
  #Loop through plots
  for (j in 1:nplots){
    
    # #Plot effect
    # plot.effect[j] ~ dnorm(0, sd = sd_plot)
    # 
    #Set initial condition for "first" observation
      mu[j,1] ~ dunif(0.01,1)
    
  #Loop through data points
  for(i in 2:(time_length[j]+1)){
    
      # Process model
      mu[j,i] <- b1*mu[j,i-1] #+ plot.effect[plots[j]]  #+ bx*x[j,i]
      log(pred[j,i]) ~ dnorm(mu[j,i], sd = sd_proc)
      
      # Data model
      y[j,i]  ~ dpois(pred[j,i])
  }}

})

constants <- list(time_length = time_length,
                  nplots = nplots)

data <- list(y = y)

nchain <- 3
inits <- list()
for(i in 1:nchain){
  inits[[i]] <- list(sd_proc = rgamma(1, 1, 1),
                     b1 = rnorm(1, 1, 1))
}

#model$initializeInfo()

nimble.out <- nimbleMCMC(code = tick_model,
                           data = data,
                           inits = inits,
                           constants = constants,
                           monitors = c("sd_proc","b1"),
                           niter = 10000,
                           nchains = 3,
                           samplesAsCodaMCMC = TRUE)

plot(nimble.out) #BOOM
gelman.diag(nimble.out)  ## BOOM!! :-)
summary(nimble.out)


#Haven't gotten to this point yet
burnin <- 2000                               
nimble.burn <- window(nimble.out, start=burnin)

plot(nimble.burn) #
effectiveSize(nimble.burn)
gelman.diag(nimble.burn)  ## determine convergence


##STOPPED ADAPTING HERE
chain <- nimble.burn %>%
  tidybayes::spread_draws(theta1, theta2, theta4, sd_data)

pred_function <- function(p1, temp, group_i){
  p1[group_i] * temp[i]
}
```



Added by Sarah 22 Mar 21:
```{r}
###Goals this week : find reliable priors and dynamic model to mess with in the nimble framework. You gotta represent a couple of different sites with different populations. Historically some of the sites have had zero count and some have had a far number. Try to figure out 


unique(ticks$siteID)


ticks%>% filter(siteID == "TALL") %>% ggplot(aes(x= epiWeek, y= ixodes_scapularis, color= plotID))+
  geom_point()

ticks%>% filter(siteID == "TALL") %>% ggplot(aes(x= epiWeek, y= ambloyomma_americanum, color= plotID))+
  geom_point()

ticks_drivers<- full_join(ticks, drivers, by= "plotID")


ticks_drivers %>% filter(siteID == "TALL") %>% ggplot(aes(x=  ambloyomma_americanum, y= tmean..degrees.C., color= plotID))+
  geom_point()

```

